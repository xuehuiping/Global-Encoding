{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "conda create --name env_GE python=3.5\n",
    "conda activate env_GE\n",
    "pip install torch==0.3.1\n",
    "pip install pyrouge\n",
    "pip install jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xuehp/git/Global-Encoding\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "(env_GE) huihui@192 data1 % scp 1_sample.txt xuehp@haomeiya002:~/git/Global-Encoding/data1/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting lxml\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ab/23/4491c457ceb7f0b9f4050b2ddcf012defa1fb5659c5c0a82f3bbe60ce1ec/lxml-4.5.2-cp35-cp35m-manylinux1_x86_64.whl (5.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.5MB 7.8MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "Successfully installed lxml-4.5.2\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting sklearn\n",
      "Collecting scikit-learn (from sklearn)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/42/ec/32310181e803f5d22e0dd33eb18924489b2f8d08cf5b6e116a93a6a5d1c6/scikit_learn-0.22.2.post1-cp35-cp35m-manylinux1_x86_64.whl (7.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.0MB 6.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.17.0 (from scikit-learn->sklearn)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c1/60/8cbf00c0deb50a971e6e3a015fb32513960a92867df979870a454481817c/scipy-1.4.1-cp35-cp35m-manylinux1_x86_64.whl (26.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 26.0MB 1.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /home/xuehp/anaconda3/envs/env_GE/lib/python3.5/site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Collecting joblib>=0.11 (from scikit-learn->sklearn)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl\n",
      "Installing collected packages: scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.14.1 scikit-learn-0.22.2.post1 scipy-1.4.1 sklearn-0.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building source vocabulary...\n",
      "data1/train.src: length limit = 0, truncate length = 0\n",
      "Max length of data1/train.src = 132\n",
      "Created dictionary of size 2996 (pruned from 2996)\n",
      "Building target vocabulary...\n",
      "data1/train.tgt: length limit = 0, truncate length = 0\n",
      "Max length of data1/train.tgt = 30\n",
      "Created dictionary of size 2105 (pruned from 2105)\n",
      "Preparing training ...\n",
      "Processing data1/train.src & data1/train.tgt ...\n",
      "Prepared 1025 sentences (0 and 0 ignored due to length == 0 or > )\n",
      "Preparing validation ...\n",
      "Processing data1/valid.src & data1/valid.tgt ...\n",
      "Prepared 505 sentences (0 and 0 ignored due to length == 0 or > )\n",
      "Preparing test ...\n",
      "Processing data1/test.src & data1/test.tgt ...\n",
      "Prepared 755 sentences (0 and 0 ignored due to length == 0 or > )\n",
      "Saving source vocabulary to 'data2/src.dict'...\n",
      "Saving source vocabulary to 'data2/tgt.dict'...\n"
     ]
    }
   ],
   "source": [
    "!python preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"train_cpu.py\", line 16, in <module>\r\n",
      "    import models\r\n",
      "  File \"/home/xuehp/git/Global-Encoding/models/__init__.py\", line 2, in <module>\r\n",
      "    from .optims import *\r\n",
      "  File \"/home/xuehp/git/Global-Encoding/models/optims.py\", line 2, in <module>\r\n",
      "    from torch.nn.utils import clip_grad_norm_\r\n",
      "ImportError: cannot import name 'clip_grad_norm_'\r\n"
     ]
    }
   ],
   "source": [
    "!python train_cpu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting torch==0.4.1\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f9/4e/1bcb4688b7506c340ca6ba5b9f57f4ad3b59a193bba365bf2b51e9e4bb3e/torch-0.4.1-cp35-cp35m-manylinux1_x86_64.whl (519.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 519.5MB 72kB/s  eta 0:00:01   16% |█████▎                          | 85.4MB 551kB/s eta 0:13:08    93% |█████████████████████████████▊  | 483.4MB 57.5MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "  Found existing installation: torch 0.3.1\n",
      "    Uninstalling torch-0.3.1:\n",
      "      Successfully uninstalled torch-0.3.1\n",
      "Successfully installed torch-0.4.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==0.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"train_cpu.py\", line 21, in <module>\r\n",
      "    import matplotlib\r\n",
      "ImportError: No module named 'matplotlib'\r\n"
     ]
    }
   ],
   "source": [
    "!python train_cpu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting matplotlib\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/89/61/465fb3bfba684b0f53b5c4829c3c89e86e6fe9fdcdfda93e38f1788090f0/matplotlib-3.0.3-cp35-cp35m-manylinux1_x86_64.whl (13.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.0MB 3.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ee/18/4cd2e84c6aff0c6a50479118083d20b9e676e5175a913c0ea76d700fc244/kiwisolver-1.1.0-cp35-cp35m-manylinux1_x86_64.whl (90kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 42.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/xuehp/anaconda3/envs/env_GE/lib/python3.5/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/xuehp/anaconda3/envs/env_GE/lib/python3.5/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /home/xuehp/anaconda3/envs/env_GE/lib/python3.5/site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: setuptools in /home/xuehp/anaconda3/envs/env_GE/lib/python3.5/site-packages (from kiwisolver>=1.0.1->matplotlib) (40.2.0)\n",
      "Requirement already satisfied: six in /home/xuehp/anaconda3/envs/env_GE/lib/python3.5/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Installing collected packages: kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.1.0 matplotlib-3.0.3\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xuehp/git/Global-Encoding/utils/misc_utils.py:13: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\n",
      "  return AttrDict(yaml.load(open(path, 'r')))\r\n",
      "loading data...\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"train_cpu.py\", line 321, in <module>\r\n",
      "    main()\r\n",
      "  File \"train_cpu.py\", line 293, in main\r\n",
      "    print_log, log_path = build_log()\r\n",
      "  File \"train_cpu.py\", line 257, in build_log\r\n",
      "    os.mkdir(config.logF)\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'experiments/lcsts/'\r\n"
     ]
    }
   ],
   "source": [
    "!python train_cpu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p experiments/lcsts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xuehp/git/Global-Encoding/utils/misc_utils.py:13: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  return AttrDict(yaml.load(open(path, 'r')))\n",
      "loading data...\n",
      "\n",
      "hidden_size:\t16\n",
      "length_norm:\tTrue\n",
      "eval_interval:\t100\n",
      "config:\tlcsts.yaml\n",
      "epoch:\t20\n",
      "logF:\texperiments/lcsts/\n",
      "learning_rate:\t0.0003\n",
      "schesamp:\tFalse\n",
      "save_interval:\t30\n",
      "tgt_vocab_size:\t2105\n",
      "optim:\tadam\n",
      "schedule:\tFalse\n",
      "log:\t\n",
      "restore:\t\n",
      "start_decay_at:\t6\n",
      "shared_vocab:\tTrue\n",
      "num_processes:\t4\n",
      "bidirectional:\tTrue\n",
      "learning_rate_decay:\t0.5\n",
      "module:\tseq2seq\n",
      "dropout:\t0.0\n",
      "char:\tFalse\n",
      "dec_num_layers:\t3\n",
      "metrics:\t['rouge']\n",
      "split_num:\t0\n",
      "unk:\tTrue\n",
      "gpus:\t[]\n",
      "data:\t/home/xuehp/git/Global-Encoding/data2/\n",
      "src_vocab_size:\t2996\n",
      "model:\tseq2seq\n",
      "enc_num_layers:\t3\n",
      "pool_size:\t0\n",
      "beam_size:\t10\n",
      "swish:\tTrue\n",
      "refF:\t\n",
      "max_grad_norm:\t10\n",
      "seed:\t1234\n",
      "max_split:\t0\n",
      "attention:\tluong_gate\n",
      "cell:\tlstm\n",
      "batch_size:\t16\n",
      "emb_size:\t16\n",
      "scale:\t1\n",
      "max_time_step:\t50\n",
      "mode:\ttrain\n",
      "use_cuda:\tFalse\n",
      "pretrain:\t\n",
      "selfatt:\tTrue\n",
      "building model...\n",
      "\n",
      "hidden_size:\t16\n",
      "length_norm:\tTrue\n",
      "eval_interval:\t100\n",
      "config:\tlcsts.yaml\n",
      "epoch:\t20\n",
      "logF:\texperiments/lcsts/\n",
      "learning_rate:\t0.0003\n",
      "schesamp:\tFalse\n",
      "save_interval:\t30\n",
      "tgt_vocab_size:\t2105\n",
      "optim:\tadam\n",
      "schedule:\tFalse\n",
      "log:\t\n",
      "restore:\t\n",
      "start_decay_at:\t6\n",
      "shared_vocab:\tTrue\n",
      "num_processes:\t4\n",
      "bidirectional:\tTrue\n",
      "learning_rate_decay:\t0.5\n",
      "module:\tseq2seq\n",
      "dropout:\t0.0\n",
      "char:\tFalse\n",
      "dec_num_layers:\t3\n",
      "metrics:\t['rouge']\n",
      "split_num:\t0\n",
      "unk:\tTrue\n",
      "gpus:\t[]\n",
      "data:\t/home/xuehp/git/Global-Encoding/data2/\n",
      "src_vocab_size:\t2996\n",
      "model:\tseq2seq\n",
      "enc_num_layers:\t3\n",
      "pool_size:\t0\n",
      "beam_size:\t10\n",
      "swish:\tTrue\n",
      "refF:\t\n",
      "max_grad_norm:\t10\n",
      "seed:\t1234\n",
      "max_split:\t0\n",
      "attention:\tluong_gate\n",
      "cell:\tlstm\n",
      "batch_size:\t16\n",
      "emb_size:\t16\n",
      "scale:\t1\n",
      "max_time_step:\t50\n",
      "mode:\ttrain\n",
      "use_cuda:\tFalse\n",
      "pretrain:\t\n",
      "selfatt:\tTrue\n",
      "\n",
      "seq2seq(\n",
      "  (encoder): rnn_encoder(\n",
      "    (embedding): Embedding(2996, 16)\n",
      "    (sw1): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (sw3): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): ReLU()\n",
      "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (sw33): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): ReLU()\n",
      "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (7): ReLU()\n",
      "      (8): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): GLU(dim=-1)\n",
      "      (2): Dropout(p=0.0)\n",
      "    )\n",
      "    (filter_linear): Linear(in_features=48, out_features=16, bias=True)\n",
      "    (tanh): Tanh()\n",
      "    (sigmoid): Sigmoid()\n",
      "    (attention): luong_gate_attention(\n",
      "      (linear_enc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (linear_in): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (linear_out): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (softmax): Softmax()\n",
      "    )\n",
      "    (rnn): LSTM(16, 16, num_layers=3, bidirectional=True)\n",
      "  )\n",
      "  (decoder): rnn_decoder(\n",
      "    (embedding): Embedding(2996, 16)\n",
      "    (rnn): StackedLSTM(\n",
      "      (dropout): Dropout(p=0.0)\n",
      "      (layers): ModuleList(\n",
      "        (0): LSTMCell(16, 16)\n",
      "        (1): LSTMCell(16, 16)\n",
      "        (2): LSTMCell(16, 16)\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=16, out_features=2105, bias=True)\n",
      "    (linear_): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "    (attention): luong_gate_attention(\n",
      "      (linear_enc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (linear_in): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (linear_out): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (softmax): Softmax()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0)\n",
      "  )\n",
      "  (log_softmax): LogSoftmax()\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "\n",
      "total number of parameters: 116649\n",
      "\n",
      "1 / 20\n",
      "2 / 20===================================================>..............................]  Step: 221ms | Tot: 21s247m 65/100 \n",
      " [=====================================================================================>]  Step: 324ms | Tot: 32s871m 100/100 \n",
      "epoch:   2, loss: 761.723, time: 33.204, updates:      100, accuracy: 0.62\n",
      "evaluating after 100 updates...\n",
      "Error!..................................................................................]  Step: 109ms | Tot: 0m 1/505 97/505 \n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Traceback (most recent call last):\n",
      "  File \"train_cpu.py\", line 321, in <module>\n",
      "    main()\n",
      "  File \"train_cpu.py\", line 312, in main\n",
      "    train_model(model, data, optim, i, params)\n",
      "  File \"train_cpu.py\", line 169, in train_model\n",
      "    score = eval_model(model, data, params)\n",
      "  File \"train_cpu.py\", line 239, in eval_model\n",
      "    score[metric] = getattr(utils, metric)(reference, candidate, params['log_path'], params['log'], config)\n",
      "  File \"/home/xuehp/git/Global-Encoding/utils/metrics.py\", line 52, in rouge\n",
      "    r = pyrouge.Rouge155()\n",
      "  File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/site-packages/pyrouge/Rouge155.py\", line 88, in __init__\n",
      "    self.__set_rouge_dir(rouge_dir)\n",
      "  File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/site-packages/pyrouge/Rouge155.py\", line 402, in __set_rouge_dir\n",
      "    self._home_dir = self.__get_rouge_home_dir_from_settings()\n",
      "  File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/site-packages/pyrouge/Rouge155.py\", line 416, in __get_rouge_home_dir_from_settings\n",
      "    with open(self._settings_file) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/xuehp/.pyrouge/settings.ini'\n"
     ]
    }
   ],
   "source": [
    "!python train_cpu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-04 19:12:39,688 [MainThread  ] [INFO ]  Set ROUGE home directory to RELEASE-1.5.5/.\r\n"
     ]
    }
   ],
   "source": [
    "!pyrouge_set_rouge_path RELEASE-1.5.5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xuehp/git/Global-Encoding\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改文件内容：\n",
    "\n",
    "```\n",
    "xuehp@haomeiya002:~/.pyrouge$ pwd\n",
    "/home/xuehp/.pyrouge\n",
    "xuehp@haomeiya002:~/.pyrouge$ vi settings.ini \n",
    "```\n",
    "\n",
    "```\n",
    "[pyrouge settings]\n",
    "home_dir = /home/xuehp/git/Global-Encoding/RELEASE-1.5.5/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xuehp/git/Global-Encoding/utils/misc_utils.py:13: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  return AttrDict(yaml.load(open(path, 'r')))\n",
      "loading data...\n",
      "\n",
      "epoch:\t20\n",
      "shared_vocab:\tTrue\n",
      "logF:\texperiments/lcsts/\n",
      "max_split:\t0\n",
      "metrics:\t['rouge']\n",
      "schedule:\tFalse\n",
      "learning_rate:\t0.0003\n",
      "char:\tFalse\n",
      "eval_interval:\t100\n",
      "attention:\tluong_gate\n",
      "bidirectional:\tTrue\n",
      "scale:\t1\n",
      "seed:\t1234\n",
      "config:\tlcsts.yaml\n",
      "swish:\tTrue\n",
      "unk:\tTrue\n",
      "cell:\tlstm\n",
      "save_interval:\t30\n",
      "model:\tseq2seq\n",
      "restore:\t\n",
      "enc_num_layers:\t3\n",
      "optim:\tadam\n",
      "hidden_size:\t16\n",
      "gpus:\t[]\n",
      "dropout:\t0.0\n",
      "src_vocab_size:\t2996\n",
      "split_num:\t0\n",
      "mode:\ttrain\n",
      "refF:\t\n",
      "pretrain:\t\n",
      "num_processes:\t4\n",
      "pool_size:\t0\n",
      "batch_size:\t16\n",
      "module:\tseq2seq\n",
      "use_cuda:\tFalse\n",
      "log:\t\n",
      "schesamp:\tFalse\n",
      "max_grad_norm:\t10\n",
      "dec_num_layers:\t3\n",
      "selfatt:\tTrue\n",
      "beam_size:\t10\n",
      "max_time_step:\t50\n",
      "data:\t/home/xuehp/git/Global-Encoding/data2/\n",
      "length_norm:\tTrue\n",
      "learning_rate_decay:\t0.5\n",
      "emb_size:\t16\n",
      "tgt_vocab_size:\t2105\n",
      "start_decay_at:\t6\n",
      "building model...\n",
      "\n",
      "epoch:\t20\n",
      "shared_vocab:\tTrue\n",
      "logF:\texperiments/lcsts/\n",
      "max_split:\t0\n",
      "metrics:\t['rouge']\n",
      "schedule:\tFalse\n",
      "learning_rate:\t0.0003\n",
      "char:\tFalse\n",
      "eval_interval:\t100\n",
      "attention:\tluong_gate\n",
      "bidirectional:\tTrue\n",
      "scale:\t1\n",
      "seed:\t1234\n",
      "config:\tlcsts.yaml\n",
      "swish:\tTrue\n",
      "unk:\tTrue\n",
      "cell:\tlstm\n",
      "save_interval:\t30\n",
      "model:\tseq2seq\n",
      "restore:\t\n",
      "enc_num_layers:\t3\n",
      "optim:\tadam\n",
      "hidden_size:\t16\n",
      "gpus:\t[]\n",
      "dropout:\t0.0\n",
      "src_vocab_size:\t2996\n",
      "split_num:\t0\n",
      "mode:\ttrain\n",
      "refF:\t\n",
      "pretrain:\t\n",
      "num_processes:\t4\n",
      "pool_size:\t0\n",
      "batch_size:\t16\n",
      "module:\tseq2seq\n",
      "use_cuda:\tFalse\n",
      "log:\t\n",
      "schesamp:\tFalse\n",
      "max_grad_norm:\t10\n",
      "dec_num_layers:\t3\n",
      "selfatt:\tTrue\n",
      "beam_size:\t10\n",
      "max_time_step:\t50\n",
      "data:\t/home/xuehp/git/Global-Encoding/data2/\n",
      "length_norm:\tTrue\n",
      "learning_rate_decay:\t0.5\n",
      "emb_size:\t16\n",
      "tgt_vocab_size:\t2105\n",
      "start_decay_at:\t6\n",
      "\n",
      "seq2seq(\n",
      "  (encoder): rnn_encoder(\n",
      "    (embedding): Embedding(2996, 16)\n",
      "    (sw1): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (sw3): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): ReLU()\n",
      "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (sw33): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): ReLU()\n",
      "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (7): ReLU()\n",
      "      (8): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): GLU(dim=-1)\n",
      "      (2): Dropout(p=0.0)\n",
      "    )\n",
      "    (filter_linear): Linear(in_features=48, out_features=16, bias=True)\n",
      "    (tanh): Tanh()\n",
      "    (sigmoid): Sigmoid()\n",
      "    (attention): luong_gate_attention(\n",
      "      (linear_enc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (linear_in): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (linear_out): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (softmax): Softmax()\n",
      "    )\n",
      "    (rnn): LSTM(16, 16, num_layers=3, bidirectional=True)\n",
      "  )\n",
      "  (decoder): rnn_decoder(\n",
      "    (embedding): Embedding(2996, 16)\n",
      "    (rnn): StackedLSTM(\n",
      "      (dropout): Dropout(p=0.0)\n",
      "      (layers): ModuleList(\n",
      "        (0): LSTMCell(16, 16)\n",
      "        (1): LSTMCell(16, 16)\n",
      "        (2): LSTMCell(16, 16)\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=16, out_features=2105, bias=True)\n",
      "    (linear_): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "    (attention): luong_gate_attention(\n",
      "      (linear_enc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (linear_in): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (linear_out): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (softmax): Softmax()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0)\n",
      "  )\n",
      "  (log_softmax): LogSoftmax()\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "\n",
      "total number of parameters: 116649\n",
      "\n",
      "1 / 20\n",
      "2 / 20===================================================>..............................]  Step: 221ms | Tot: 21s273m 65/100 \n",
      " [=====================================================================================>]  Step: 324ms | Tot: 32s917m 100/100 \n",
      "epoch:   2, loss: 761.723, time: 33.253, updates:      100, accuracy: 0.62\n",
      "evaluating after 100 updates...\n",
      "Error!..................................................................................]  Step: 110ms | Tot: 0m 1/505 97/505 \n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train_cpu.py\", line 321, in <module>\n",
      "    main()\n",
      "  File \"train_cpu.py\", line 312, in main\n",
      "    train_model(model, data, optim, i, params)\n",
      "  File \"train_cpu.py\", line 169, in train_model\n",
      "    score = eval_model(model, data, params)\n",
      "  File \"train_cpu.py\", line 239, in eval_model\n",
      "    score[metric] = getattr(utils, metric)(reference, candidate, params['log_path'], params['log'], config)\n",
      "  File \"/home/xuehp/git/Global-Encoding/utils/metrics.py\", line 58, in rouge\n",
      "    rouge_results = r.convert_and_evaluate()\n",
      "  File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/site-packages/pyrouge/Rouge155.py\", line 361, in convert_and_evaluate\n",
      "    rouge_output = self.evaluate(system_id, rouge_args)\n",
      "  File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/site-packages/pyrouge/Rouge155.py\", line 336, in evaluate\n",
      "    rouge_output = check_output(command).decode(\"UTF-8\")\n",
      "  File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/subprocess.py\", line 316, in check_output\n",
      "    **kwargs).stdout\n",
      "  File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/subprocess.py\", line 383, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/subprocess.py\", line 676, in __init__\n",
      "    restore_signals, start_new_session)\n",
      "  File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/subprocess.py\", line 1289, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg)\n",
      "PermissionError: [Errno 13] Permission denied\n"
     ]
    }
   ],
   "source": [
    "!python train_cpu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for xuehp: \n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install libxml-parser-perl\n",
    "\n",
    "# 命令行运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xuehp/git/Global-Encoding/utils/misc_utils.py:13: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  return AttrDict(yaml.load(open(path, 'r')))\n",
      "loading data...\n",
      "\n",
      "restore:\t\n",
      "swish:\tTrue\n",
      "use_cuda:\tFalse\n",
      "eval_interval:\t100\n",
      "epoch:\t20\n",
      "dec_num_layers:\t3\n",
      "num_processes:\t4\n",
      "batch_size:\t16\n",
      "seed:\t1234\n",
      "attention:\tluong_gate\n",
      "learning_rate_decay:\t0.5\n",
      "schesamp:\tFalse\n",
      "start_decay_at:\t6\n",
      "bidirectional:\tTrue\n",
      "pretrain:\t\n",
      "cell:\tlstm\n",
      "log:\t\n",
      "learning_rate:\t0.0003\n",
      "emb_size:\t16\n",
      "dropout:\t0.0\n",
      "unk:\tTrue\n",
      "tgt_vocab_size:\t2105\n",
      "max_split:\t0\n",
      "selfatt:\tTrue\n",
      "data:\t/home/xuehp/git/Global-Encoding/data2/\n",
      "char:\tFalse\n",
      "split_num:\t0\n",
      "enc_num_layers:\t3\n",
      "hidden_size:\t16\n",
      "length_norm:\tTrue\n",
      "scale:\t1\n",
      "schedule:\tFalse\n",
      "model:\tseq2seq\n",
      "optim:\tadam\n",
      "pool_size:\t0\n",
      "max_time_step:\t50\n",
      "save_interval:\t30\n",
      "mode:\ttrain\n",
      "max_grad_norm:\t10\n",
      "logF:\texperiments/lcsts/\n",
      "src_vocab_size:\t2996\n",
      "beam_size:\t10\n",
      "gpus:\t[]\n",
      "module:\tseq2seq\n",
      "shared_vocab:\tTrue\n",
      "config:\tlcsts.yaml\n",
      "refF:\t\n",
      "metrics:\t['rouge']\n",
      "building model...\n",
      "\n",
      "restore:\t\n",
      "swish:\tTrue\n",
      "use_cuda:\tFalse\n",
      "eval_interval:\t100\n",
      "epoch:\t20\n",
      "dec_num_layers:\t3\n",
      "num_processes:\t4\n",
      "batch_size:\t16\n",
      "seed:\t1234\n",
      "attention:\tluong_gate\n",
      "learning_rate_decay:\t0.5\n",
      "schesamp:\tFalse\n",
      "start_decay_at:\t6\n",
      "bidirectional:\tTrue\n",
      "pretrain:\t\n",
      "cell:\tlstm\n",
      "log:\t\n",
      "learning_rate:\t0.0003\n",
      "emb_size:\t16\n",
      "dropout:\t0.0\n",
      "unk:\tTrue\n",
      "tgt_vocab_size:\t2105\n",
      "max_split:\t0\n",
      "selfatt:\tTrue\n",
      "data:\t/home/xuehp/git/Global-Encoding/data2/\n",
      "char:\tFalse\n",
      "split_num:\t0\n",
      "enc_num_layers:\t3\n",
      "hidden_size:\t16\n",
      "length_norm:\tTrue\n",
      "scale:\t1\n",
      "schedule:\tFalse\n",
      "model:\tseq2seq\n",
      "optim:\tadam\n",
      "pool_size:\t0\n",
      "max_time_step:\t50\n",
      "save_interval:\t30\n",
      "mode:\ttrain\n",
      "max_grad_norm:\t10\n",
      "logF:\texperiments/lcsts/\n",
      "src_vocab_size:\t2996\n",
      "beam_size:\t10\n",
      "gpus:\t[]\n",
      "module:\tseq2seq\n",
      "shared_vocab:\tTrue\n",
      "config:\tlcsts.yaml\n",
      "refF:\t\n",
      "metrics:\t['rouge']\n",
      "\n",
      "seq2seq(\n",
      "  (encoder): rnn_encoder(\n",
      "    (embedding): Embedding(2996, 16)\n",
      "    (sw1): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (sw3): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): ReLU()\n",
      "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (sw33): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): ReLU()\n",
      "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (7): ReLU()\n",
      "      (8): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): GLU(dim=-1)\n",
      "      (2): Dropout(p=0.0)\n",
      "    )\n",
      "    (filter_linear): Linear(in_features=48, out_features=16, bias=True)\n",
      "    (tanh): Tanh()\n",
      "    (sigmoid): Sigmoid()\n",
      "    (attention): luong_gate_attention(\n",
      "      (linear_enc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (linear_in): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (linear_out): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (softmax): Softmax()\n",
      "    )\n",
      "    (rnn): LSTM(16, 16, num_layers=3, bidirectional=True)\n",
      "  )\n",
      "  (decoder): rnn_decoder(\n",
      "    (embedding): Embedding(2996, 16)\n",
      "    (rnn): StackedLSTM(\n",
      "      (dropout): Dropout(p=0.0)\n",
      "      (layers): ModuleList(\n",
      "        (0): LSTMCell(16, 16)\n",
      "        (1): LSTMCell(16, 16)\n",
      "        (2): LSTMCell(16, 16)\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=16, out_features=2105, bias=True)\n",
      "    (linear_): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "    (attention): luong_gate_attention(\n",
      "      (linear_enc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (linear_in): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (linear_out): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (softmax): Softmax()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0)\n",
      "  )\n",
      "  (log_softmax): LogSoftmax()\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "\n",
      "total number of parameters: 116649\n",
      "\n",
      "1 / 20\n",
      "2 / 20===================================================>..............................]  Step: 222ms | Tot: 21s34m 65/100  \n",
      " [=====================================================================================>]  Step: 320ms | Tot: 32s479m 100/100 \n",
      "epoch:   2, loss: 761.723, time: 32.804, updates:      100, accuracy: 0.62\n",
      "evaluating after 100 updates...\n",
      "Error!..................................................................................]  Step: 112ms | Tot: 0m 1/505 97/505 \n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"train_cpu.py\", line 321, in <module>\r\n",
      "    main()\r\n",
      "  File \"train_cpu.py\", line 312, in main\r\n",
      "    train_model(model, data, optim, i, params)\r\n",
      "  File \"train_cpu.py\", line 169, in train_model\r\n",
      "    score = eval_model(model, data, params)\r\n",
      "  File \"train_cpu.py\", line 239, in eval_model\r\n",
      "    score[metric] = getattr(utils, metric)(reference, candidate, params['log_path'], params['log'], config)\r\n",
      "  File \"/home/xuehp/git/Global-Encoding/utils/metrics.py\", line 58, in rouge\r\n",
      "    rouge_results = r.convert_and_evaluate()\r\n",
      "  File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/site-packages/pyrouge/Rouge155.py\", line 361, in convert_and_evaluate\r\n",
      "    rouge_output = self.evaluate(system_id, rouge_args)\r\n",
      "  File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/site-packages/pyrouge/Rouge155.py\", line 336, in evaluate\r\n",
      "    rouge_output = check_output(command).decode(\"UTF-8\")\r\n",
      "  File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/subprocess.py\", line 316, in check_output\r\n",
      "    **kwargs).stdout\r\n",
      "  File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/subprocess.py\", line 383, in run\r\n",
      "    with Popen(*popenargs, **kwargs) as process:\r\n",
      "  File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/subprocess.py\", line 676, in __init__\r\n",
      "    restore_signals, start_new_session)\r\n",
      "  File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/subprocess.py\", line 1289, in _execute_child\r\n",
      "    raise child_exception_type(errno_num, err_msg)\r\n",
      "PermissionError: [Errno 13] Permission denied\r\n"
     ]
    }
   ],
   "source": [
    "!python train_cpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "File \"/home/xuehp/anaconda3/envs/env_GE/lib/python3.5/subprocess.py\", line 1289, in _execute_child\n",
    "    raise child_exception_type(errno_num, err_msg)\n",
    "PermissionError: [Errno 13] Permission denied\n",
    "(env_GE) xuehp@haomeiya002:~/git/Global-Encoding$ chmod 777 RELEASE-1.5.5/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xuehp/git/Global-Encoding/utils/misc_utils.py:13: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  return AttrDict(yaml.load(open(path, 'r')))\n",
      "loading data...\n",
      "\n",
      "log:\t\n",
      "logF:\texperiments/lcsts/\n",
      "restore:\t\n",
      "dropout:\t0.0\n",
      "eval_interval:\t100\n",
      "max_time_step:\t50\n",
      "enc_num_layers:\t3\n",
      "seed:\t1234\n",
      "save_interval:\t30\n",
      "src_vocab_size:\t2996\n",
      "config:\tlcsts.yaml\n",
      "optim:\tadam\n",
      "metrics:\t['bleu']\n",
      "max_split:\t0\n",
      "cell:\tlstm\n",
      "use_cuda:\tFalse\n",
      "learning_rate_decay:\t0.5\n",
      "schedule:\tFalse\n",
      "dec_num_layers:\t3\n",
      "hidden_size:\t16\n",
      "batch_size:\t16\n",
      "num_processes:\t4\n",
      "swish:\tTrue\n",
      "learning_rate:\t0.0003\n",
      "refF:\t\n",
      "tgt_vocab_size:\t2105\n",
      "shared_vocab:\tTrue\n",
      "gpus:\t[]\n",
      "scale:\t1\n",
      "char:\tFalse\n",
      "pool_size:\t0\n",
      "bidirectional:\tTrue\n",
      "mode:\ttrain\n",
      "emb_size:\t16\n",
      "attention:\tluong_gate\n",
      "unk:\tTrue\n",
      "split_num:\t0\n",
      "schesamp:\tFalse\n",
      "length_norm:\tTrue\n",
      "beam_size:\t10\n",
      "selfatt:\tTrue\n",
      "pretrain:\t\n",
      "max_grad_norm:\t10\n",
      "model:\tseq2seq\n",
      "start_decay_at:\t6\n",
      "data:\t/home/xuehp/git/Global-Encoding/data2/\n",
      "epoch:\t20\n",
      "module:\tseq2seq\n",
      "building model...\n",
      "\n",
      "log:\t\n",
      "logF:\texperiments/lcsts/\n",
      "restore:\t\n",
      "dropout:\t0.0\n",
      "eval_interval:\t100\n",
      "max_time_step:\t50\n",
      "enc_num_layers:\t3\n",
      "seed:\t1234\n",
      "save_interval:\t30\n",
      "src_vocab_size:\t2996\n",
      "config:\tlcsts.yaml\n",
      "optim:\tadam\n",
      "metrics:\t['bleu']\n",
      "max_split:\t0\n",
      "cell:\tlstm\n",
      "use_cuda:\tFalse\n",
      "learning_rate_decay:\t0.5\n",
      "schedule:\tFalse\n",
      "dec_num_layers:\t3\n",
      "hidden_size:\t16\n",
      "batch_size:\t16\n",
      "num_processes:\t4\n",
      "swish:\tTrue\n",
      "learning_rate:\t0.0003\n",
      "refF:\t\n",
      "tgt_vocab_size:\t2105\n",
      "shared_vocab:\tTrue\n",
      "gpus:\t[]\n",
      "scale:\t1\n",
      "char:\tFalse\n",
      "pool_size:\t0\n",
      "bidirectional:\tTrue\n",
      "mode:\ttrain\n",
      "emb_size:\t16\n",
      "attention:\tluong_gate\n",
      "unk:\tTrue\n",
      "split_num:\t0\n",
      "schesamp:\tFalse\n",
      "length_norm:\tTrue\n",
      "beam_size:\t10\n",
      "selfatt:\tTrue\n",
      "pretrain:\t\n",
      "max_grad_norm:\t10\n",
      "model:\tseq2seq\n",
      "start_decay_at:\t6\n",
      "data:\t/home/xuehp/git/Global-Encoding/data2/\n",
      "epoch:\t20\n",
      "module:\tseq2seq\n",
      "\n",
      "seq2seq(\n",
      "  (encoder): rnn_encoder(\n",
      "    (embedding): Embedding(2996, 16)\n",
      "    (sw1): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (sw3): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): ReLU()\n",
      "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (sw33): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): ReLU()\n",
      "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (7): ReLU()\n",
      "      (8): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): GLU(dim=-1)\n",
      "      (2): Dropout(p=0.0)\n",
      "    )\n",
      "    (filter_linear): Linear(in_features=48, out_features=16, bias=True)\n",
      "    (tanh): Tanh()\n",
      "    (sigmoid): Sigmoid()\n",
      "    (attention): luong_gate_attention(\n",
      "      (linear_enc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (linear_in): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (linear_out): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (softmax): Softmax()\n",
      "    )\n",
      "    (rnn): LSTM(16, 16, num_layers=3, bidirectional=True)\n",
      "  )\n",
      "  (decoder): rnn_decoder(\n",
      "    (embedding): Embedding(2996, 16)\n",
      "    (rnn): StackedLSTM(\n",
      "      (dropout): Dropout(p=0.0)\n",
      "      (layers): ModuleList(\n",
      "        (0): LSTMCell(16, 16)\n",
      "        (1): LSTMCell(16, 16)\n",
      "        (2): LSTMCell(16, 16)\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=16, out_features=2105, bias=True)\n",
      "    (linear_): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "    (attention): luong_gate_attention(\n",
      "      (linear_enc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (linear_in): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (linear_out): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (softmax): Softmax()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0)\n",
      "  )\n",
      "  (log_softmax): LogSoftmax()\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "\n",
      "total number of parameters: 116649\n",
      "\n",
      "1 / 20\n",
      "2 / 20===================================================>..............................]  Step: 225ms | Tot: 21s209m 65/100 \n",
      " [=====================================================================================>]  Step: 320ms | Tot: 32s811m 100/100 \n",
      "epoch:   2, loss: 761.723, time: 33.142, updates:      100, accuracy: 0.62\n",
      "evaluating after 100 updates...\n",
      "Error!..................................................................................]  Step: 111ms | Tot: 0m 1/505 97/505 \n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illegal division by zero at script/multi-bleu.perl line 142, <STDIN> line 505.\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"train_cpu.py\", line 321, in <module>\r\n",
      "    main()\r\n",
      "  File \"train_cpu.py\", line 312, in main\r\n",
      "    train_model(model, data, optim, i, params)\r\n",
      "  File \"train_cpu.py\", line 169, in train_model\r\n",
      "    score = eval_model(model, data, params)\r\n",
      "  File \"train_cpu.py\", line 239, in eval_model\r\n",
      "    score[metric] = getattr(utils, metric)(reference, candidate, params['log_path'], params['log'], config)\r\n",
      "  File \"/home/xuehp/git/Global-Encoding/utils/metrics.py\", line 33, in bleu\r\n",
      "    return float(result.split()[2][:-1])\r\n",
      "IndexError: list index out of range\r\n"
     ]
    }
   ],
   "source": [
    "# 修改评测指标为bleu\n",
    "!python train_cpu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xuehp/git/Global-Encoding/utils/misc_utils.py:13: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  return AttrDict(yaml.load(open(path, 'r')))\n",
      "loading data...\n",
      "\n",
      "data:\t/home/xuehp/git/Global-Encoding/data2/\n",
      "batch_size:\t16\n",
      "src_vocab_size:\t2996\n",
      "learning_rate_decay:\t0.5\n",
      "schesamp:\tFalse\n",
      "metrics:\t['bleu']\n",
      "length_norm:\tTrue\n",
      "max_time_step:\t50\n",
      "tgt_vocab_size:\t2105\n",
      "log:\t\n",
      "optim:\tadam\n",
      "start_decay_at:\t6\n",
      "pretrain:\t\n",
      "emb_size:\t16\n",
      "enc_num_layers:\t3\n",
      "eval_interval:\t100\n",
      "restore:\t\n",
      "use_cuda:\tFalse\n",
      "mode:\ttrain\n",
      "char:\tFalse\n",
      "module:\tseq2seq\n",
      "shared_vocab:\tTrue\n",
      "attention:\tluong_gate\n",
      "epoch:\t20\n",
      "dec_num_layers:\t3\n",
      "save_interval:\t30\n",
      "swish:\tTrue\n",
      "cell:\tlstm\n",
      "selfatt:\tTrue\n",
      "logF:\texperiments/lcsts/\n",
      "learning_rate:\t0.0003\n",
      "num_processes:\t4\n",
      "config:\tlcsts.yaml\n",
      "scale:\t1\n",
      "max_grad_norm:\t10\n",
      "split_num:\t0\n",
      "bidirectional:\tTrue\n",
      "model:\tseq2seq\n",
      "beam_size:\t10\n",
      "unk:\tTrue\n",
      "seed:\t1234\n",
      "hidden_size:\t16\n",
      "refF:\t\n",
      "pool_size:\t0\n",
      "gpus:\t[]\n",
      "dropout:\t0.0\n",
      "schedule:\tFalse\n",
      "max_split:\t0\n",
      "building model...\n",
      "\n",
      "data:\t/home/xuehp/git/Global-Encoding/data2/\n",
      "batch_size:\t16\n",
      "src_vocab_size:\t2996\n",
      "learning_rate_decay:\t0.5\n",
      "schesamp:\tFalse\n",
      "metrics:\t['bleu']\n",
      "length_norm:\tTrue\n",
      "max_time_step:\t50\n",
      "tgt_vocab_size:\t2105\n",
      "log:\t\n",
      "optim:\tadam\n",
      "start_decay_at:\t6\n",
      "pretrain:\t\n",
      "emb_size:\t16\n",
      "enc_num_layers:\t3\n",
      "eval_interval:\t100\n",
      "restore:\t\n",
      "use_cuda:\tFalse\n",
      "mode:\ttrain\n",
      "char:\tFalse\n",
      "module:\tseq2seq\n",
      "shared_vocab:\tTrue\n",
      "attention:\tluong_gate\n",
      "epoch:\t20\n",
      "dec_num_layers:\t3\n",
      "save_interval:\t30\n",
      "swish:\tTrue\n",
      "cell:\tlstm\n",
      "selfatt:\tTrue\n",
      "logF:\texperiments/lcsts/\n",
      "learning_rate:\t0.0003\n",
      "num_processes:\t4\n",
      "config:\tlcsts.yaml\n",
      "scale:\t1\n",
      "max_grad_norm:\t10\n",
      "split_num:\t0\n",
      "bidirectional:\tTrue\n",
      "model:\tseq2seq\n",
      "beam_size:\t10\n",
      "unk:\tTrue\n",
      "seed:\t1234\n",
      "hidden_size:\t16\n",
      "refF:\t\n",
      "pool_size:\t0\n",
      "gpus:\t[]\n",
      "dropout:\t0.0\n",
      "schedule:\tFalse\n",
      "max_split:\t0\n",
      "\n",
      "seq2seq(\n",
      "  (encoder): rnn_encoder(\n",
      "    (embedding): Embedding(2996, 16)\n",
      "    (sw1): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (sw3): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): ReLU()\n",
      "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (sw33): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): ReLU()\n",
      "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (7): ReLU()\n",
      "      (8): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): GLU(dim=-1)\n",
      "      (2): Dropout(p=0.0)\n",
      "    )\n",
      "    (filter_linear): Linear(in_features=48, out_features=16, bias=True)\n",
      "    (tanh): Tanh()\n",
      "    (sigmoid): Sigmoid()\n",
      "    (attention): luong_gate_attention(\n",
      "      (linear_enc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (linear_in): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (linear_out): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (softmax): Softmax()\n",
      "    )\n",
      "    (rnn): LSTM(16, 16, num_layers=3, bidirectional=True)\n",
      "  )\n",
      "  (decoder): rnn_decoder(\n",
      "    (embedding): Embedding(2996, 16)\n",
      "    (rnn): StackedLSTM(\n",
      "      (dropout): Dropout(p=0.0)\n",
      "      (layers): ModuleList(\n",
      "        (0): LSTMCell(16, 16)\n",
      "        (1): LSTMCell(16, 16)\n",
      "        (2): LSTMCell(16, 16)\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=16, out_features=2105, bias=True)\n",
      "    (linear_): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "    (attention): luong_gate_attention(\n",
      "      (linear_enc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (linear_in): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (linear_out): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (softmax): Softmax()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0)\n",
      "  )\n",
      "  (log_softmax): LogSoftmax()\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "\n",
      "total number of parameters: 116649\n",
      "\n",
      "1 / 20\n",
      "2 / 20===================================================>..............................]  Step: 230ms | Tot: 21s29m 65/100  \n",
      " [=====================================================================================>]  Step: 316ms | Tot: 32s397m 100/100 \n",
      "epoch:   2, loss: 761.723, time: 32.720, updates:      100, accuracy: 0.62\n",
      "evaluating after 100 updates...\n",
      "Error!..................................................................................]  Step: 109ms | Tot: 0m 1/505 97/505 \n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illegal division by zero at script/multi-bleu.perl line 142, <STDIN> line 505.\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"train_cpu.py\", line 321, in <module>\r\n",
      "    main()\r\n",
      "  File \"train_cpu.py\", line 312, in main\r\n",
      "    train_model(model, data, optim, i, params)\r\n",
      "  File \"train_cpu.py\", line 169, in train_model\r\n",
      "    score = eval_model(model, data, params)\r\n",
      "  File \"train_cpu.py\", line 239, in eval_model\r\n",
      "    score[metric] = getattr(utils, metric)(reference, candidate, params['log_path'], params['log'], config)\r\n",
      "  File \"/home/xuehp/git/Global-Encoding/utils/metrics.py\", line 34, in bleu\r\n",
      "    return float(result.split()[2][:-1])\r\n",
      "IndexError: list index out of range\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python train_cpu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xuehp/git/Global-Encoding/utils/misc_utils.py:13: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  return AttrDict(yaml.load(open(path, 'r')))\n",
      "loading data...\n",
      "\n",
      "restore:\t\n",
      "pretrain:\t\n",
      "epoch:\t20\n",
      "batch_size:\t16\n",
      "optim:\tadam\n",
      "model:\tseq2seq\n",
      "swish:\tTrue\n",
      "attention:\tluong_gate\n",
      "use_cuda:\tFalse\n",
      "max_grad_norm:\t10\n",
      "beam_size:\t10\n",
      "eval_interval:\t100\n",
      "enc_num_layers:\t3\n",
      "shared_vocab:\tTrue\n",
      "scale:\t1\n",
      "seed:\t1234\n",
      "mode:\ttrain\n",
      "selfatt:\tTrue\n",
      "hidden_size:\t16\n",
      "char:\tFalse\n",
      "max_time_step:\t50\n",
      "start_decay_at:\t6\n",
      "log:\t\n",
      "tgt_vocab_size:\t2105\n",
      "schedule:\tFalse\n",
      "gpus:\t[]\n",
      "save_interval:\t30\n",
      "dropout:\t0.0\n",
      "config:\tlcsts.yaml\n",
      "learning_rate:\t0.03\n",
      "cell:\tlstm\n",
      "bidirectional:\tTrue\n",
      "unk:\tTrue\n",
      "learning_rate_decay:\t0.5\n",
      "module:\tseq2seq\n",
      "split_num:\t0\n",
      "pool_size:\t0\n",
      "logF:\texperiments/lcsts/\n",
      "max_split:\t0\n",
      "dec_num_layers:\t3\n",
      "refF:\t\n",
      "num_processes:\t4\n",
      "length_norm:\tTrue\n",
      "schesamp:\tFalse\n",
      "emb_size:\t16\n",
      "src_vocab_size:\t2996\n",
      "data:\t/home/xuehp/git/Global-Encoding/data2/\n",
      "metrics:\t['bleu']\n",
      "building model...\n",
      "\n",
      "restore:\t\n",
      "pretrain:\t\n",
      "epoch:\t20\n",
      "batch_size:\t16\n",
      "optim:\tadam\n",
      "model:\tseq2seq\n",
      "swish:\tTrue\n",
      "attention:\tluong_gate\n",
      "use_cuda:\tFalse\n",
      "max_grad_norm:\t10\n",
      "beam_size:\t10\n",
      "eval_interval:\t100\n",
      "enc_num_layers:\t3\n",
      "shared_vocab:\tTrue\n",
      "scale:\t1\n",
      "seed:\t1234\n",
      "mode:\ttrain\n",
      "selfatt:\tTrue\n",
      "hidden_size:\t16\n",
      "char:\tFalse\n",
      "max_time_step:\t50\n",
      "start_decay_at:\t6\n",
      "log:\t\n",
      "tgt_vocab_size:\t2105\n",
      "schedule:\tFalse\n",
      "gpus:\t[]\n",
      "save_interval:\t30\n",
      "dropout:\t0.0\n",
      "config:\tlcsts.yaml\n",
      "learning_rate:\t0.03\n",
      "cell:\tlstm\n",
      "bidirectional:\tTrue\n",
      "unk:\tTrue\n",
      "learning_rate_decay:\t0.5\n",
      "module:\tseq2seq\n",
      "split_num:\t0\n",
      "pool_size:\t0\n",
      "logF:\texperiments/lcsts/\n",
      "max_split:\t0\n",
      "dec_num_layers:\t3\n",
      "refF:\t\n",
      "num_processes:\t4\n",
      "length_norm:\tTrue\n",
      "schesamp:\tFalse\n",
      "emb_size:\t16\n",
      "src_vocab_size:\t2996\n",
      "data:\t/home/xuehp/git/Global-Encoding/data2/\n",
      "metrics:\t['bleu']\n",
      "\n",
      "seq2seq(\n",
      "  (encoder): rnn_encoder(\n",
      "    (embedding): Embedding(2996, 16)\n",
      "    (sw1): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (sw3): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): ReLU()\n",
      "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (sw33): Sequential(\n",
      "      (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): ReLU()\n",
      "      (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (7): ReLU()\n",
      "      (8): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): GLU(dim=-1)\n",
      "      (2): Dropout(p=0.0)\n",
      "    )\n",
      "    (filter_linear): Linear(in_features=48, out_features=16, bias=True)\n",
      "    (tanh): Tanh()\n",
      "    (sigmoid): Sigmoid()\n",
      "    (attention): luong_gate_attention(\n",
      "      (linear_enc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (linear_in): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (linear_out): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.1)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.1)\n",
      "      )\n",
      "      (softmax): Softmax()\n",
      "    )\n",
      "    (rnn): LSTM(16, 16, num_layers=3, bidirectional=True)\n",
      "  )\n",
      "  (decoder): rnn_decoder(\n",
      "    (embedding): Embedding(2996, 16)\n",
      "    (rnn): StackedLSTM(\n",
      "      (dropout): Dropout(p=0.0)\n",
      "      (layers): ModuleList(\n",
      "        (0): LSTMCell(16, 16)\n",
      "        (1): LSTMCell(16, 16)\n",
      "        (2): LSTMCell(16, 16)\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=16, out_features=2105, bias=True)\n",
      "    (linear_): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "    (attention): luong_gate_attention(\n",
      "      (linear_enc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (linear_in): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (linear_out): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (1): SELU()\n",
      "        (2): Dropout(p=0.0)\n",
      "        (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (4): SELU()\n",
      "        (5): Dropout(p=0.0)\n",
      "      )\n",
      "      (softmax): Softmax()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0)\n",
      "  )\n",
      "  (log_softmax): LogSoftmax()\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "\n",
      "total number of parameters: 116649\n",
      "\n",
      "1 / 20\n",
      "2 / 20===================================================>..............................]  Step: 226ms | Tot: 20s915m 65/100 \n",
      " [=====================================================================================>]  Step: 318ms | Tot: 32s456m 100/100 \n",
      "epoch:   2, loss: 677.609, time: 32.780, updates:      100, accuracy: 5.39\n",
      "evaluating after 100 updates...\n",
      "Use of uninitialized value in division (/) at script/multi-bleu.perl line 127, <STDIN> line 505. 1s143ms | Tot: 0m 1/505 05 05 \n",
      "BLEU = 0.00, 3.4/0.1/0.0/0.0 (BP=1.000, ratio=1.447, hyp_len=13639, ref_len=9424)\n",
      "BLEU = 0.00, 3.4/0.1/0.0/0.0 (BP=1.000, ratio=1.447, hyp_len=13639, ref_len=9424)\n",
      "\n",
      "3 / 20====================>.............................................................]  Step: 213ms | Tot: 9s489m 30/100 \n",
      "4 / 20============================================================================>.....]  Step: 212ms | Tot: 30s929m 95/100 \n",
      " [=====================================================================================>]  Step: 318ms | Tot: 32s538m 100/100 \n",
      "epoch:   4, loss: 653.754, time: 32.901, updates:      200, accuracy: 6.46\n",
      "evaluating after 200 updates...\n",
      "Use of uninitialized value in division (/) at script/multi-bleu.perl line 127, <STDIN> line 505. 638ms | Tot: 0m 1/505 /505 5   \n",
      "BLEU = 0.00, 3.8/0.5/0.1/0.0 (BP=1.000, ratio=1.393, hyp_len=13132, ref_len=9424)\n",
      "BLEU = 0.00, 3.8/0.5/0.1/0.0 (BP=1.000, ratio=1.393, hyp_len=13132, ref_len=9424)\n",
      "\n",
      "5 / 20==============================================>...................................]  Step: 226ms | Tot: 19s305m 60/100 \n",
      " [=====================================================================================>]  Step: 308ms | Tot: 32s407m 100/100 \n",
      "epoch:   5, loss: 632.982, time: 32.754, updates:      300, accuracy: 7.47\n",
      "evaluating after 300 updates...\n",
      "BLEU = 0.68, 7.2/1.7/0.4/0.1 (BP=0.812, ratio=0.828, hyp_len=7799, ref_len=9424)........]  Step: 233ms | Tot: 0m 1/505 97/505 \n",
      "BLEU = 0.68, 7.2/1.7/0.4/0.1 (BP=0.812, ratio=0.828, hyp_len=7799, ref_len=9424)\n",
      "\n",
      "6 / 20================>.................................................................]  Step: 214ms | Tot: 7s816m 25/100 \n",
      "Decaying learning rate to 0.015===============================================>.........]  Step: 177ms | Tot: 29s268m 90/100 \n",
      "7 / 20\n",
      " [=====================================================================================>]  Step: 340ms | Tot: 32s546m 100/100 \n",
      "epoch:   7, loss: 619.171, time: 32.904, updates:      400, accuracy: 8.19\n",
      "evaluating after 400 updates...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 0.50, 5.3/1.4/0.3/0.0 (BP=1.000, ratio=1.259, hyp_len=11868, ref_len=9424).......]  Step: 1s163ms | Tot: 0m 1/505 05 5  \n",
      "BLEU = 0.50, 5.3/1.4/0.3/0.0 (BP=1.000, ratio=1.259, hyp_len=11868, ref_len=9424)\n",
      "\n",
      "Decaying learning rate to 0.0075================>.......................................]  Step: 160ms | Tot: 17s540m 55/100 \n",
      "8 / 20\n",
      " [=====================================================================================>]  Step: 315ms | Tot: 32s262m 100/100 \n",
      "epoch:   8, loss: 593.030, time: 32.601, updates:      500, accuracy: 9.14\n",
      "evaluating after 500 updates...\n",
      "Error!..................................................................................]  Step: 614ms | Tot: 0m 1/505 /505 5   \n",
      "Error!\n",
      "BLEU = 0.65, 6.9/1.5/0.5/0.1 (BP=0.708, ratio=0.744, hyp_len=7007, ref_len=9424)\n",
      "BLEU = 0.65, 6.9/1.5/0.5/0.1 (BP=0.708, ratio=0.744, hyp_len=7007, ref_len=9424)\n",
      "\n",
      "Decaying learning rate to 0.00375.......................................................]  Step: 226ms | Tot: 6s282m 20/100 \n",
      "9 / 20\n",
      "Decaying learning rate to 0.001875========================================>.............]  Step: 222ms | Tot: 27s809m 85/100 \n",
      "10 / 20\n",
      " [=====================================================================================>]  Step: 327ms | Tot: 32s677m 100/100 \n",
      "epoch:  10, loss: 574.858, time: 33.039, updates:      600, accuracy: 9.96\n",
      "evaluating after 600 updates...\n",
      "Error!..................................................................................]  Step: 543ms | Tot: 0m 1/505 05 05   \n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "BLEU = 0.53, 7.6/1.7/0.4/0.1 (BP=0.621, ratio=0.678, hyp_len=6385, ref_len=9424)\n",
      "BLEU = 0.53, 7.6/1.7/0.4/0.1 (BP=0.621, ratio=0.678, hyp_len=6385, ref_len=9424)\n",
      "\n",
      "Decaying learning rate to 0.0009375=========>...........................................]  Step: 217ms | Tot: 16s95m 50/100  \n",
      "11 / 20\n",
      " [=====================================================================================>]  Step: 337ms | Tot: 32s587m 100/100 \n",
      "epoch:  11, loss: 561.170, time: 32.948, updates:      700, accuracy: 10.69\n",
      "evaluating after 700 updates...\n",
      "Error!..................................................................................]  Step: 514ms | Tot: 0m 1/505 97/505 \n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "BLEU = 0.58, 9.1/2.1/0.6/0.2 (BP=0.470, ratio=0.570, hyp_len=5367, ref_len=9424)\n",
      "BLEU = 0.58, 9.1/2.1/0.6/0.2 (BP=0.470, ratio=0.570, hyp_len=5367, ref_len=9424)\n",
      "\n",
      "Decaying learning rate to 0.00046875....................................................]  Step: 217ms | Tot: 4s512m 15/100 \n",
      "12 / 20\n",
      "Decaying learning rate to 0.000234375================================>..................]  Step: 214ms | Tot: 25s595m 80/100 \n",
      "13 / 20\n",
      " [=====================================================================================>]  Step: 306ms | Tot: 32s47m 100/100 \n",
      "epoch:  13, loss: 558.758, time: 32.391, updates:      800, accuracy: 10.86\n",
      "evaluating after 800 updates...\n",
      "Error!..................................................................................]  Step: 515ms | Tot: 0m 1/505 97/505 \n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "BLEU = 0.47, 8.9/1.9/0.5/0.2 (BP=0.426, ratio=0.539, hyp_len=5084, ref_len=9424)\n",
      "BLEU = 0.47, 8.9/1.9/0.5/0.2 (BP=0.426, ratio=0.539, hyp_len=5084, ref_len=9424)\n",
      "\n",
      "Decaying learning rate to 0.000117187==>................................................]  Step: 221ms | Tot: 14s346m 45/100 \n",
      "14 / 20\n",
      " [=====================================================================================>]  Step: 316ms | Tot: 32s398m 100/100 \n",
      "epoch:  14, loss: 559.008, time: 32.760, updates:      900, accuracy: 10.79\n",
      "evaluating after 900 updates...\n",
      "Error!..................................................................................]  Step: 543ms | Tot: 0m 1/505 7/505  \n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "BLEU = 0.47, 8.5/1.8/0.5/0.2 (BP=0.439, ratio=0.548, hyp_len=5168, ref_len=9424)\n",
      "BLEU = 0.47, 8.5/1.8/0.5/0.2 (BP=0.439, ratio=0.548, hyp_len=5168, ref_len=9424)\n",
      "\n",
      "Decaying learning rate to 5.85937e-05...................................................]  Step: 186ms | Tot: 2s843m 10/100 \n",
      "15 / 20\n",
      "Decaying learning rate to 2.92969e-05============================>......................]  Step: 207ms | Tot: 24s53m 75/100  \n",
      "16 / 20\n",
      " [=====================================================================================>]  Step: 335ms | Tot: 32s331m 100/100 \n",
      "epoch:  16, loss: 556.949, time: 32.691, updates:     1000, accuracy: 10.97\n",
      "evaluating after 1000 updates...\n",
      "Error!..................................................................................]  Step: 535ms | Tot: 0m 1/505 7/505   \n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "BLEU = 0.50, 8.5/1.8/0.5/0.2 (BP=0.454, ratio=0.559, hyp_len=5264, ref_len=9424)\n",
      "BLEU = 0.50, 8.5/1.8/0.5/0.2 (BP=0.454, ratio=0.559, hyp_len=5264, ref_len=9424)\n",
      "\n",
      "Decaying learning rate to 1.46484e-05...................................................]  Step: 210ms | Tot: 12s877m 40/100 \n",
      "17 / 20\n",
      " [=====================================================================================>]  Step: 323ms | Tot: 32s731m 100/100 \n",
      "epoch:  17, loss: 558.628, time: 33.079, updates:     1100, accuracy: 10.76\n",
      "evaluating after 1100 updates...\n",
      "Error!..................................................................................]  Step: 534ms | Tot: 0m 1/505 7/505   \n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "BLEU = 0.49, 8.5/1.8/0.5/0.2 (BP=0.449, ratio=0.555, hyp_len=5232, ref_len=9424)\n",
      "BLEU = 0.49, 8.5/1.8/0.5/0.2 (BP=0.449, ratio=0.555, hyp_len=5232, ref_len=9424)\n",
      "\n",
      "Decaying learning rate to 7.32422e-06...................................................]  Step: 209ms | Tot: 1s206m 5/100 \n",
      "18 / 20\n",
      "Decaying learning rate to 3.66211e-06========================>..........................]  Step: 190ms | Tot: 22s594m 70/100 \n",
      "19 / 20\n",
      " [=====================================================================================>]  Step: 325ms | Tot: 32s474m 100/100 \n",
      "epoch:  19, loss: 557.281, time: 32.847, updates:     1200, accuracy: 10.92\n",
      "evaluating after 1200 updates...\n",
      "Error!..................................................................................]  Step: 537ms | Tot: 0m 1/505 7/505   \n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "BLEU = 0.49, 8.5/1.8/0.5/0.2 (BP=0.451, ratio=0.557, hyp_len=5245, ref_len=9424)\n",
      "BLEU = 0.49, 8.5/1.8/0.5/0.2 (BP=0.451, ratio=0.557, hyp_len=5245, ref_len=9424)\n",
      "\n",
      "Decaying learning rate to 1.83105e-06...................................................]  Step: 192ms | Tot: 11s81m 35/100  \n",
      "20 / 20\n",
      " [=====================================================================================>]  Step: 205ms | Tot: 32s428m 100/100 \n",
      "epoch:  20, loss: 558.332, time: 32.788, updates:     1300, accuracy: 10.92\n",
      "evaluating after 1300 updates...\n",
      "Error!..................................................................................]  Step: 538ms | Tot: 0m 1/505 05 05   \n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "Error!\n",
      "BLEU = 0.49, 8.5/1.8/0.5/0.2 (BP=0.448, ratio=0.554, hyp_len=5224, ref_len=9424)\n",
      "BLEU = 0.49, 8.5/1.8/0.5/0.2 (BP=0.448, ratio=0.554, hyp_len=5224, ref_len=9424)\n",
      "\n",
      "Decaying learning rate to 9.15527e-07\n",
      "Best bleu score: 0.68\n"
     ]
    }
   ],
   "source": [
    "!python train_cpu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
